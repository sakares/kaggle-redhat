{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Random Forest Classifier\n",
    "Simple Random Forest implementation for redhat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A bit of setup\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import cross_validation\n",
    "from sklearn.learning_curve import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_dimen(dataset,column,toreplace):\n",
    "    for index,i in dataset[column].duplicated(keep=False).iteritems():\n",
    "        if i==False:\n",
    "            dataset.set_value(index,column,toreplace)\n",
    "    return dataset\n",
    "    \n",
    "def act_data_treatment(dsname):\n",
    "    dataset = dsname\n",
    "    \n",
    "    for col in list(dataset.columns):\n",
    "        if col not in ['people_id', 'activity_id', 'date', 'char_38', 'outcome']:\n",
    "            if dataset[col].dtype == 'object':\n",
    "                dataset[col].fillna('type 0', inplace=True)\n",
    "                dataset[col] = dataset[col].apply(lambda x: x.split(' ')[1]).astype(np.int32)\n",
    "            elif dataset[col].dtype == 'bool':\n",
    "                dataset[col] = dataset[col].astype(np.int8)\n",
    "    \n",
    "    dataset['year'] = dataset['date'].dt.year\n",
    "    dataset['month'] = dataset['date'].dt.month\n",
    "    dataset['day'] = dataset['date'].dt.day\n",
    "    dataset['isweekend'] = (dataset['date'].dt.weekday >= 5).astype(int)\n",
    "    dataset = dataset.drop('date', axis = 1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2197291, 14)\n",
      "Test data shape: (498687, 13)\n",
      "People data shape: (189118, 41)\n"
     ]
    }
   ],
   "source": [
    "act_train_data = pd.read_csv(\"act_train.csv\",dtype={'people_id': np.str, 'activity_id': np.str, 'outcome': np.int8}, parse_dates=['date'])\n",
    "act_test_data  = pd.read_csv(\"act_test.csv\", dtype={'people_id': np.str, 'activity_id': np.str}, parse_dates=['date'])\n",
    "people_data    = pd.read_csv(\"people.csv\", dtype={'people_id': np.str, 'activity_id': np.str, 'char_38': np.int32}, parse_dates=['date'])\n",
    "\n",
    "act_train_data=act_train_data.drop('char_10',axis=1)\n",
    "act_test_data=act_test_data.drop('char_10',axis=1)\n",
    "\n",
    "print(\"Train data shape: \" + format(act_train_data.shape))\n",
    "print(\"Test data shape: \" + format(act_test_data.shape))\n",
    "print(\"People data shape: \" + format(people_data.shape))\n",
    "\n",
    "act_train_data  = act_data_treatment(act_train_data)\n",
    "act_test_data   = act_data_treatment(act_test_data)\n",
    "people_data = act_data_treatment(people_data)\n",
    "\n",
    "train = act_train_data.merge(people_data, on='people_id', how='left', left_index=True)\n",
    "test  = act_test_data.merge(people_data, on='people_id', how='left', left_index=True)\n",
    "\n",
    "del act_train_data\n",
    "del act_test_data\n",
    "del people_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=train.sort_values(['people_id'], ascending=[1])\n",
    "test=test.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "train_columns = train.columns.values\n",
    "test_columns = test.columns.values\n",
    "features = list(set(train_columns) & set(test_columns))\n",
    "\n",
    "train.fillna('NA', inplace=True)\n",
    "test.fillna('NA', inplace=True)\n",
    "\n",
    "y = train.outcome\n",
    "train=train.drop('outcome',axis=1)\n",
    "\n",
    "whole=pd.concat([train,test],ignore_index=True)\n",
    "categorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\n",
    "for category in categorical:\n",
    "    whole=reduce_dimen(whole,category,9999999)\n",
    "    \n",
    "X=whole[:len(train)]\n",
    "X_test=whole[len(train):]\n",
    "\n",
    "del train\n",
    "del whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (2197291, 31271)\n",
      "Test data: (498687, 31271)\n",
      "###########\n",
      "One Hot enconded Test Dataset Script\n"
     ]
    }
   ],
   "source": [
    "X=X.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "X = X[features].drop(['people_id', 'activity_id'], axis = 1)\n",
    "X_test = X_test[features].drop(['people_id', 'activity_id'], axis = 1)\n",
    "\n",
    "categorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\n",
    "not_categorical=[]\n",
    "for category in X.columns:\n",
    "    if category not in categorical:\n",
    "        not_categorical.append(category)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc=enc.fit(pd.concat([X[categorical],X_test[categorical]]))\n",
    "X_cat_sparse=enc.transform(X[categorical])\n",
    "X_test_cat_sparse=enc.transform(X_test[categorical])\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "X_sparse=hstack((X[not_categorical], X_cat_sparse))\n",
    "X_test_sparse=hstack((X_test[not_categorical], X_test_cat_sparse))\n",
    "\n",
    "print(\"Training data: \" + format(X_sparse.shape))\n",
    "print(\"Test data: \" + format(X_test_sparse.shape))\n",
    "print(\"###########\")\n",
    "print(\"One Hot enconded Test Dataset Script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train and Validation Data\n",
    "load all data from pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.887776\n",
      "Will train until train-auc hasn't improved in 10 rounds.\n",
      "[1]\ttrain-auc:0.895355\n",
      "[2]\ttrain-auc:0.90321\n",
      "[3]\ttrain-auc:0.911401\n",
      "[4]\ttrain-auc:0.919584\n",
      "[5]\ttrain-auc:0.927466\n",
      "[6]\ttrain-auc:0.934822\n",
      "[7]\ttrain-auc:0.941604\n",
      "[8]\ttrain-auc:0.947911\n",
      "[9]\ttrain-auc:0.953769\n",
      "[10]\ttrain-auc:0.959155\n",
      "[11]\ttrain-auc:0.964043\n",
      "[12]\ttrain-auc:0.968386\n",
      "[13]\ttrain-auc:0.972177\n",
      "[14]\ttrain-auc:0.975439\n",
      "[15]\ttrain-auc:0.978211\n",
      "[16]\ttrain-auc:0.980549\n",
      "[17]\ttrain-auc:0.982512\n",
      "[18]\ttrain-auc:0.984152\n",
      "[19]\ttrain-auc:0.985523\n",
      "[20]\ttrain-auc:0.986671\n",
      "[21]\ttrain-auc:0.987637\n",
      "[22]\ttrain-auc:0.988458\n",
      "[23]\ttrain-auc:0.989162\n",
      "[24]\ttrain-auc:0.989773\n",
      "[25]\ttrain-auc:0.99031\n",
      "[26]\ttrain-auc:0.990786\n",
      "[27]\ttrain-auc:0.991213\n",
      "[28]\ttrain-auc:0.991597\n",
      "[29]\ttrain-auc:0.991945\n",
      "[30]\ttrain-auc:0.992263\n",
      "[31]\ttrain-auc:0.992553\n",
      "[32]\ttrain-auc:0.99282\n",
      "[33]\ttrain-auc:0.993065\n",
      "[34]\ttrain-auc:0.993291\n",
      "[35]\ttrain-auc:0.9935\n",
      "[36]\ttrain-auc:0.993694\n",
      "[37]\ttrain-auc:0.993875\n",
      "[38]\ttrain-auc:0.994043\n",
      "[39]\ttrain-auc:0.994201\n",
      "[40]\ttrain-auc:0.994348\n",
      "[41]\ttrain-auc:0.994486\n",
      "[42]\ttrain-auc:0.994616\n",
      "[43]\ttrain-auc:0.994738\n",
      "[44]\ttrain-auc:0.994853\n",
      "[45]\ttrain-auc:0.994962\n",
      "[46]\ttrain-auc:0.995064\n",
      "[47]\ttrain-auc:0.995161\n",
      "[48]\ttrain-auc:0.995253\n",
      "[49]\ttrain-auc:0.995339\n",
      "[50]\ttrain-auc:0.995422\n",
      "[51]\ttrain-auc:0.995499\n",
      "[52]\ttrain-auc:0.995573\n",
      "[53]\ttrain-auc:0.995643\n",
      "[54]\ttrain-auc:0.99571\n",
      "[55]\ttrain-auc:0.995773\n",
      "[56]\ttrain-auc:0.995833\n",
      "[57]\ttrain-auc:0.995891\n",
      "[58]\ttrain-auc:0.995946\n",
      "[59]\ttrain-auc:0.995998\n",
      "[60]\ttrain-auc:0.996047\n",
      "[61]\ttrain-auc:0.996095\n",
      "[62]\ttrain-auc:0.99614\n",
      "[63]\ttrain-auc:0.996184\n",
      "[64]\ttrain-auc:0.996225\n",
      "[65]\ttrain-auc:0.996265\n",
      "[66]\ttrain-auc:0.996303\n",
      "[67]\ttrain-auc:0.996339\n",
      "[68]\ttrain-auc:0.996374\n",
      "[69]\ttrain-auc:0.996407\n",
      "[70]\ttrain-auc:0.996439\n",
      "[71]\ttrain-auc:0.99647\n",
      "[72]\ttrain-auc:0.996499\n",
      "[73]\ttrain-auc:0.996527\n",
      "[74]\ttrain-auc:0.996554\n",
      "[75]\ttrain-auc:0.99658\n",
      "[76]\ttrain-auc:0.996605\n",
      "[77]\ttrain-auc:0.996629\n",
      "[78]\ttrain-auc:0.996652\n",
      "[79]\ttrain-auc:0.996674\n",
      "[80]\ttrain-auc:0.996695\n",
      "[81]\ttrain-auc:0.996715\n",
      "[82]\ttrain-auc:0.996735\n",
      "[83]\ttrain-auc:0.996753\n",
      "[84]\ttrain-auc:0.996771\n",
      "[85]\ttrain-auc:0.996788\n",
      "[86]\ttrain-auc:0.996805\n",
      "[87]\ttrain-auc:0.99682\n",
      "[88]\ttrain-auc:0.996835\n",
      "[89]\ttrain-auc:0.99685\n",
      "[90]\ttrain-auc:0.996863\n",
      "[91]\ttrain-auc:0.996877\n",
      "[92]\ttrain-auc:0.996889\n",
      "[93]\ttrain-auc:0.996901\n",
      "[94]\ttrain-auc:0.996913\n",
      "[95]\ttrain-auc:0.996924\n",
      "[96]\ttrain-auc:0.996935\n",
      "[97]\ttrain-auc:0.996945\n",
      "[98]\ttrain-auc:0.996954\n",
      "[99]\ttrain-auc:0.996964\n",
      "[100]\ttrain-auc:0.996973\n",
      "[101]\ttrain-auc:0.996981\n",
      "[102]\ttrain-auc:0.996989\n",
      "[103]\ttrain-auc:0.996997\n",
      "[104]\ttrain-auc:0.997005\n",
      "[105]\ttrain-auc:0.997012\n",
      "[106]\ttrain-auc:0.997019\n",
      "[107]\ttrain-auc:0.997026\n",
      "[108]\ttrain-auc:0.997032\n",
      "[109]\ttrain-auc:0.997039\n",
      "[110]\ttrain-auc:0.997045\n",
      "[111]\ttrain-auc:0.99705\n",
      "[112]\ttrain-auc:0.997056\n",
      "[113]\ttrain-auc:0.997061\n",
      "[114]\ttrain-auc:0.997067\n",
      "[115]\ttrain-auc:0.997072\n",
      "[116]\ttrain-auc:0.997076\n",
      "[117]\ttrain-auc:0.997081\n",
      "[118]\ttrain-auc:0.997086\n",
      "[119]\ttrain-auc:0.99709\n",
      "[120]\ttrain-auc:0.997094\n",
      "[121]\ttrain-auc:0.997098\n",
      "[122]\ttrain-auc:0.997102\n",
      "[123]\ttrain-auc:0.997106\n",
      "[124]\ttrain-auc:0.99711\n",
      "[125]\ttrain-auc:0.997113\n",
      "[126]\ttrain-auc:0.997117\n",
      "[127]\ttrain-auc:0.99712\n",
      "[128]\ttrain-auc:0.997123\n",
      "[129]\ttrain-auc:0.997126\n",
      "[130]\ttrain-auc:0.997129\n",
      "[131]\ttrain-auc:0.997132\n",
      "[132]\ttrain-auc:0.997135\n",
      "[133]\ttrain-auc:0.997138\n",
      "[134]\ttrain-auc:0.997141\n",
      "[135]\ttrain-auc:0.997143\n",
      "[136]\ttrain-auc:0.997146\n",
      "[137]\ttrain-auc:0.997148\n",
      "[138]\ttrain-auc:0.99715\n",
      "[139]\ttrain-auc:0.997152\n",
      "[140]\ttrain-auc:0.997155\n",
      "[141]\ttrain-auc:0.997157\n",
      "[142]\ttrain-auc:0.997159\n",
      "[143]\ttrain-auc:0.997161\n",
      "[144]\ttrain-auc:0.997163\n",
      "[145]\ttrain-auc:0.997165\n",
      "[146]\ttrain-auc:0.997166\n",
      "[147]\ttrain-auc:0.997168\n",
      "[148]\ttrain-auc:0.99717\n",
      "[149]\ttrain-auc:0.997171\n",
      "[150]\ttrain-auc:0.997173\n",
      "[151]\ttrain-auc:0.997175\n",
      "[152]\ttrain-auc:0.997176\n",
      "[153]\ttrain-auc:0.997178\n",
      "[154]\ttrain-auc:0.997179\n",
      "[155]\ttrain-auc:0.99718\n",
      "[156]\ttrain-auc:0.997182\n",
      "[157]\ttrain-auc:0.997183\n",
      "[158]\ttrain-auc:0.997184\n",
      "[159]\ttrain-auc:0.997185\n",
      "[160]\ttrain-auc:0.997187\n",
      "[161]\ttrain-auc:0.997188\n",
      "[162]\ttrain-auc:0.997189\n",
      "[163]\ttrain-auc:0.99719\n",
      "[164]\ttrain-auc:0.997191\n",
      "[165]\ttrain-auc:0.997192\n",
      "[166]\ttrain-auc:0.997193\n",
      "[167]\ttrain-auc:0.997194\n",
      "[168]\ttrain-auc:0.997195\n",
      "[169]\ttrain-auc:0.997196\n",
      "[170]\ttrain-auc:0.997196\n",
      "[171]\ttrain-auc:0.997197\n",
      "[172]\ttrain-auc:0.997198\n",
      "[173]\ttrain-auc:0.997199\n",
      "[174]\ttrain-auc:0.9972\n",
      "[175]\ttrain-auc:0.9972\n",
      "[176]\ttrain-auc:0.997201\n",
      "[177]\ttrain-auc:0.997202\n",
      "[178]\ttrain-auc:0.997202\n",
      "[179]\ttrain-auc:0.997203\n",
      "[180]\ttrain-auc:0.997204\n",
      "[181]\ttrain-auc:0.997204\n",
      "[182]\ttrain-auc:0.997205\n",
      "[183]\ttrain-auc:0.997205\n",
      "[184]\ttrain-auc:0.997206\n",
      "[185]\ttrain-auc:0.997206\n",
      "[186]\ttrain-auc:0.997207\n",
      "[187]\ttrain-auc:0.997207\n",
      "[188]\ttrain-auc:0.997208\n",
      "[189]\ttrain-auc:0.997208\n",
      "[190]\ttrain-auc:0.997209\n",
      "[191]\ttrain-auc:0.997209\n",
      "[192]\ttrain-auc:0.99721\n",
      "[193]\ttrain-auc:0.99721\n",
      "[194]\ttrain-auc:0.997211\n",
      "[195]\ttrain-auc:0.997211\n",
      "[196]\ttrain-auc:0.997211\n",
      "[197]\ttrain-auc:0.997212\n",
      "[198]\ttrain-auc:0.997212\n",
      "[199]\ttrain-auc:0.997212\n",
      "[200]\ttrain-auc:0.997213\n",
      "[201]\ttrain-auc:0.997213\n",
      "[202]\ttrain-auc:0.997213\n",
      "[203]\ttrain-auc:0.997214\n",
      "[204]\ttrain-auc:0.997214\n",
      "[205]\ttrain-auc:0.997214\n",
      "[206]\ttrain-auc:0.997215\n",
      "[207]\ttrain-auc:0.997215\n",
      "[208]\ttrain-auc:0.997215\n",
      "[209]\ttrain-auc:0.997216\n",
      "[210]\ttrain-auc:0.997216\n",
      "[211]\ttrain-auc:0.997216\n",
      "[212]\ttrain-auc:0.997216\n",
      "[213]\ttrain-auc:0.997217\n",
      "[214]\ttrain-auc:0.997217\n",
      "[215]\ttrain-auc:0.997217\n",
      "[216]\ttrain-auc:0.997217\n",
      "[217]\ttrain-auc:0.997218\n",
      "[218]\ttrain-auc:0.997218\n",
      "[219]\ttrain-auc:0.997218\n",
      "[220]\ttrain-auc:0.997218\n",
      "[221]\ttrain-auc:0.997218\n",
      "[222]\ttrain-auc:0.997219\n",
      "[223]\ttrain-auc:0.997219\n",
      "[224]\ttrain-auc:0.997219\n",
      "[225]\ttrain-auc:0.997219\n",
      "[226]\ttrain-auc:0.997219\n",
      "[227]\ttrain-auc:0.99722\n",
      "[228]\ttrain-auc:0.99722\n",
      "[229]\ttrain-auc:0.99722\n",
      "[230]\ttrain-auc:0.99722\n",
      "[231]\ttrain-auc:0.99722\n",
      "[232]\ttrain-auc:0.997221\n",
      "[233]\ttrain-auc:0.997221\n",
      "[234]\ttrain-auc:0.997221\n",
      "[235]\ttrain-auc:0.997221\n",
      "[236]\ttrain-auc:0.997221\n",
      "[237]\ttrain-auc:0.997221\n",
      "[238]\ttrain-auc:0.997222\n",
      "[239]\ttrain-auc:0.997222\n",
      "[240]\ttrain-auc:0.997222\n",
      "[241]\ttrain-auc:0.997222\n",
      "[242]\ttrain-auc:0.997222\n",
      "[243]\ttrain-auc:0.997222\n",
      "[244]\ttrain-auc:0.997223\n",
      "[245]\ttrain-auc:0.997223\n",
      "[246]\ttrain-auc:0.997223\n",
      "[247]\ttrain-auc:0.997223\n",
      "[248]\ttrain-auc:0.997223\n",
      "[249]\ttrain-auc:0.997223\n",
      "[250]\ttrain-auc:0.997224\n",
      "[251]\ttrain-auc:0.997224\n",
      "[252]\ttrain-auc:0.997224\n",
      "[253]\ttrain-auc:0.997224\n",
      "[254]\ttrain-auc:0.997224\n",
      "[255]\ttrain-auc:0.997224\n",
      "[256]\ttrain-auc:0.997224\n",
      "[257]\ttrain-auc:0.997225\n",
      "[258]\ttrain-auc:0.997225\n",
      "[259]\ttrain-auc:0.997225\n",
      "[260]\ttrain-auc:0.997225\n",
      "[261]\ttrain-auc:0.997225\n",
      "[262]\ttrain-auc:0.997225\n",
      "[263]\ttrain-auc:0.997225\n",
      "[264]\ttrain-auc:0.997226\n",
      "[265]\ttrain-auc:0.997226\n",
      "[266]\ttrain-auc:0.997226\n",
      "[267]\ttrain-auc:0.997226\n",
      "[268]\ttrain-auc:0.997226\n",
      "[269]\ttrain-auc:0.997226\n",
      "[270]\ttrain-auc:0.997226\n",
      "[271]\ttrain-auc:0.997226\n",
      "[272]\ttrain-auc:0.997226\n",
      "[273]\ttrain-auc:0.997227\n",
      "[274]\ttrain-auc:0.997227\n",
      "[275]\ttrain-auc:0.997227\n",
      "[276]\ttrain-auc:0.997227\n",
      "[277]\ttrain-auc:0.997227\n",
      "[278]\ttrain-auc:0.997227\n",
      "[279]\ttrain-auc:0.997227\n",
      "[280]\ttrain-auc:0.997227\n",
      "[281]\ttrain-auc:0.997227\n",
      "[282]\ttrain-auc:0.997228\n",
      "[283]\ttrain-auc:0.997228\n",
      "[284]\ttrain-auc:0.997228\n",
      "[285]\ttrain-auc:0.997228\n",
      "[286]\ttrain-auc:0.997228\n",
      "[287]\ttrain-auc:0.997228\n",
      "[288]\ttrain-auc:0.997228\n",
      "[289]\ttrain-auc:0.997228\n",
      "[290]\ttrain-auc:0.997228\n",
      "[291]\ttrain-auc:0.997229\n",
      "[292]\ttrain-auc:0.997229\n",
      "[293]\ttrain-auc:0.997229\n",
      "[294]\ttrain-auc:0.997229\n",
      "[295]\ttrain-auc:0.997229\n",
      "[296]\ttrain-auc:0.997229\n",
      "[297]\ttrain-auc:0.997229\n",
      "[298]\ttrain-auc:0.997229\n",
      "[299]\ttrain-auc:0.997229\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_sparse,label=y)\n",
    "dtest = xgb.DMatrix(X_test_sparse)\n",
    "\n",
    "param = {'max_depth':10, 'eta':0.02, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "param['subsample'] = 0.7\n",
    "param['colsample_bytree']= 0.7\n",
    "param['min_child_weight'] = 0\n",
    "param['booster'] = \"gblinear\"\n",
    "\n",
    "watchlist  = [(dtrain,'train')]\n",
    "num_round = 300\n",
    "early_stopping_rounds=10\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist,early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bst = xgb.train(param, dtrain, num_round, watchlist,early_stopping_rounds=early_stopping_rounds)\n",
    "# result = xgb.cv(params, dtrain, num_boost_round=10, evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, evals_result=None, verbose_eval=True, learning_rates=None, xgb_model=None, callbacks=None)\n",
    "result = xgb.cv(param, dtrain, num_boost_round=300, nfold=3, early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-771b05d08e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.887405\n",
      "1    0.894957\n",
      "2    0.902785\n",
      "3    0.910944\n",
      "4    0.919101\n",
      "5    0.926954\n",
      "6    0.934287\n",
      "7    0.941040\n",
      "8    0.947329\n",
      "9    0.953163\n",
      "Name: test-auc-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve\n",
    "To estimate how doing well on the classifer by checking the training score and the cross-validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'xgboost' has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-20d6e9d2411e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'XGBOOST learningcurve'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_first_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'xgboost' has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "xgb.plot.tree(feature_names='XGBOOST learningcurve', model=bst, n_first_tree=2, width=600, height=4800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test Case\n",
    "To predict the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ypred = bst.predict(dtest)\n",
    "output = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred })\n",
    "output.head()\n",
    "output.to_csv('without_leak_xgb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
